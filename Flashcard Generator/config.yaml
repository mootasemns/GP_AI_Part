term_extraction:
  num_terms: 5  
  model_checkpoint: "t5-small"  
  max_length: 100  
  num_beams: 4  

model:
  checkpoint: "t5-small"  

preprocessing:
  max_input_length: 512
  max_target_length: 128

flashcard_generation:
  num_flashcards: 5
  fine_tuned_model_directory: './fine_tuned_model'

data:
  train_split: 'train[:80%]'
  validation_split: 'train[80%:]'

output:
  tokenized_train_dataset: 'tokenized_train_dataset'
  tokenized_valid_dataset: 'tokenized_valid_dataset'
